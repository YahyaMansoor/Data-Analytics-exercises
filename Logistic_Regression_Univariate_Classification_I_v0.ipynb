{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YahyaMansoor/Data-Analytics-exercises/blob/main/Logistic_Regression_Univariate_Classification_I_v0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q61PZrHf6Upi"
      },
      "source": [
        "#  Logistic Regression - Univariate Classification I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpBm40T56pwx"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze9uSJt-I-0E"
      },
      "source": [
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "In today's class, you will learn to classify or predict whether a person is suffering from heart disease or not based on just cholesterol values by deploying two most commonly used classification-based machine learning algorithms:\n",
        "\n",
        "1. Random Forest Classifier\n",
        "2. Logistic Regression\n",
        "\n",
        "Before we start, let's first recall the attributes or columns of the dataset.\n",
        "\n",
        "**Data Description**\n",
        "\n",
        "The Heart Disease UCI dataset contains data collected on 14 different attributes by examining 303 patients. The dataset focuses only on differentiating patients having heart disease; labelled as value 1 and those not having heart disease; labelled as value 0. The 14 attributes (or columns) are as follows:\n",
        "\n",
        "|Columns|Description|\n",
        "|-|-|\n",
        "|age|age in years|\n",
        "|sex|sex (1 = male; 0 = female)|\n",
        "|cp|chest pain type (4 values)|\n",
        "|trestbps|resting blood pressure (in mm Hg on admission to the hospital)|\n",
        "|chol|serum cholesterol in $\\frac{mg}{dl}$|\n",
        "|fbs|fasting blood sugar > 120 $\\frac{mg}{dl}$|\n",
        "|restecg|resting electrocardiographic results (values 0, 1, 2)|\n",
        "|thalach|maximum heart rate achieved|\n",
        "|exang|exercise induced angina (1 = yes; 0 = no)|\n",
        "|oldpeak|ST depression induced by exercise relative to rest|\n",
        "|slope|the slope of the peak exercise ST segment|\n",
        "|ca|number of major vessels (0-3) colored by fluoroscopy|\n",
        "|thal|A blood disorder called thalassemia|\n",
        "|target|1 = presence of heart disease; 0 = absence of heart disease|\n",
        "\n",
        "**Source:** https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E46b0Q_xQxVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HJNbSYx0Qy5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpKI2pWEtREK"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2UBkl1AZuRc"
      },
      "source": [
        "#### Activity 1: Loading Data\n",
        "\n",
        "Load the heart disease dataset. Here's the dataset link:\n",
        "\n",
        "https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/uci-heart-disease/heart.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmRB05lddS--",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "e51b7573-f28e-455e-a40a-07c43298f42c"
      },
      "source": [
        "# S1.1: Import the required modules and load the heart disease dataset. Also, display the first five rows.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "csv_file = 'https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/uci-heart-disease/heart.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
              "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
              "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
              "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
              "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   0     1       1  \n",
              "1   0     2       1  \n",
              "2   0     2       1  \n",
              "3   0     2       1  \n",
              "4   0     2       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9bf492b-fcc4-4c98-8d5b-a0b601c8fd73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9bf492b-fcc4-4c98-8d5b-a0b601c8fd73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9bf492b-fcc4-4c98-8d5b-a0b601c8fd73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9bf492b-fcc4-4c98-8d5b-a0b601c8fd73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1a-clG-jqPr"
      },
      "source": [
        "Let's first look at the complete information on the `df` DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2x3F5XtkAGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "231d64ec-d6c8-4f3a-db16-127c3d238a9f"
      },
      "source": [
        "# S1.2: Apply the 'info()' function on the 'df' DataFrame.\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trestbps  303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalach   303 non-null    int64  \n",
            " 8   exang     303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slope     303 non-null    int64  \n",
            " 11  ca        303 non-null    int64  \n",
            " 12  thal      303 non-null    int64  \n",
            " 13  target    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgnxI54ckEb6"
      },
      "source": [
        "You can see there are 303 entries for each column and no missing values. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al16HfwffBFB"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpw7DeLczN3f"
      },
      "source": [
        "#### Activity 2: Imbalanced Data^\n",
        "\n",
        "The target variable `target` has two values: `0` and `1`. This means that our dataset is composed of two classes or labels:\n",
        "\n",
        " - Class `0` - Patients NOT having heart disease \n",
        " - Class `1` - Patients having heart disease\n",
        "\n",
        "Such problems are known as **binary classification** problem where the target attribute can have only two possible values (for e.g. `0` and `1`).\n",
        "\n",
        "Before we start building the model, let us find out whether our dataset is balanced or not i.e. whether class distribution is uniform among all the classes. An imbalanced dataset means that the number of observations belonging to one class is significantly lower than that of the other class. Such datasets will result in a biased classifier which will hamper the results.\n",
        "\n",
        "As our dataset has two classes, then balanced data would mean 50% observations for each class. Let us calculate the number of observations for each class. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEVBxNQQThSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d249993f-82e5-46f6-9df8-5fa0e68f40b1"
      },
      "source": [
        "# S2.1 Print the number of records in each label and their percentage in the 'target' column\n",
        "# Print the number of records with and without heart disease\n",
        "print(\"Number of records in each label are\")\n",
        "print(df['target'].value_counts())\n",
        "\n",
        "# Print the percentage of each label\n",
        "print(\"\\nPercentage of records in each label are\")\n",
        "print(df['target'].value_counts() * 100 / df.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records in each label are\n",
            "1    165\n",
            "0    138\n",
            "Name: target, dtype: int64\n",
            "\n",
            "Percentage of records in each label are\n",
            "1    54.455446\n",
            "0    45.544554\n",
            "Name: target, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxfijABxvgSG"
      },
      "source": [
        "You can observe that the number of observations for each class is approximately 54% and 46% which does not seems one-sided. This means that our dataset is not imbalanced or biased towards one class or label.\n",
        "\n",
        "Let us classify the patients using Random Forest Classifier and evaluate the prediction model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eymgp4JPjDNa"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ry024CQjluDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AFcyIZMSl07"
      },
      "source": [
        "#### Activity 3: Train-Test Split\n",
        "\n",
        "We will first predict whether a person is a heart patient or not by analysing only his/her cholesterol value. Thus, the model will use only one feature or independent variable `chol` to predict the target variable `target`.\n",
        "\n",
        "Before deploying our model, let's split the `df` DataFrame into train set and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYoe69GREXWK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f9ba78-aa00-4bf0-ff24-de678d0fe2f0"
      },
      "source": [
        "# S3.1: Split the DataFrame into the train and test sets.\n",
        " \n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "X = df['chol']   # DataFrame consisting of only one feature (univariate)\n",
        "y = df['target'] # DataFrame containing the target variable\n",
        "\n",
        "# Split the DataFrame into the train and test sets such that test set has 30% of the values.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)\n",
        " \n",
        "# Reshape to 1-dimensional array.\n",
        "X_train = np.array(X_train).reshape(-1, 1)\n",
        "X_test = np.array(X_test).reshape(-1, 1)\n",
        "y_train = np.array(y_train).reshape(-1, 1)\n",
        "y_test = np.array(y_test).reshape(-1, 1)\n",
        " \n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(212, 1) (91, 1) (212, 1) (91, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5zYRSClwqFY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20N4v1sjMgGU"
      },
      "source": [
        "#### Activity 4: Applying Random Forest Classifier^^\n",
        "\n",
        "We had already explored the **Random Forest Classifier** algorithm in one of our previous classes. Let's use it to find out if it can detect the patients having heart disease accurately or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4cMnv2jyQGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e3da89-76a2-48e3-824b-73468d93b417"
      },
      "source": [
        "# S4.1: Build the Random Forest Classifier prediction model.\n",
        "# Import the required modules from the 'sklearn.ensemble' and 'sklearn.metrics' libraries\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# Build the model.\n",
        "rf_clf = RandomForestClassifier(n_jobs = -1, n_estimators = 100)\n",
        "# Call the 'fit()' function. \n",
        "rf_clf.fit(x_train, y_train)\n",
        "# Call the 'score()' function to check the accuracy score of the model.\n",
        "rf_clf.score(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8537735849056604"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPO9njW_xwS1"
      },
      "source": [
        "You may observe that the model score is pretty close to 1 or 100%. Let's perform predictions using the above model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylnKkzbrT6Jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ad5b91-4361-4bea-fcd0-1d1ac4f55267"
      },
      "source": [
        "# S4.2: Make predictions on the test dataset using the 'predict()' function.\n",
        "rf_y_pred = rf_clf.predict(x_test)\n",
        "rf_y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaoPJ7hGUBco"
      },
      "source": [
        "Let's compute the confusion matrix to evaluate the accuracy of our classifier `rf_clf`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_kCRRwloRd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0edea8f-013b-4274-f9eb-d726b3aee1f9"
      },
      "source": [
        "# S4.3: Display the results of 'confusion_matrix'\n",
        "confusion_matrix(y_test, rf_y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[24, 17],\n",
              "       [20, 30]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96m-xTok2-tt"
      },
      "source": [
        "So we got the confusion matrix for our Random Forest model. Let's recall what does a confusion matrix returns as output.\n",
        "\n",
        "In this case,\n",
        " - positive outcome $\\Rightarrow$ class `1` (patients having heart disease)\n",
        " - negative outcome $\\Rightarrow$ class `0` (patients NOT having heart disease)\n",
        "\n",
        "The confusion matrix reflects the following values:\n",
        "\n",
        "1. **True Negatives (TN)** - class `0` values **correctly** predicted as class `0`.\n",
        "\n",
        "2. **True Positives (TP)** - class `1` values **correctly** predicted as class `1`.\n",
        "\n",
        "3. **False Positives (FP)** - class `0` values **incorrectly**  predicted as class `1`.\n",
        "\n",
        "4. **False Negatives (FN)** - class `1` values **incorrectly**  predicted as class `0`.\n",
        "\n",
        "\n",
        "||Predicted Class `0`|Predicted Class `1`|    \n",
        "|-|-|-|\n",
        "|Actual Class `0`|**TN = 24**|**FP = 17**|\n",
        "|Actual Class `1`|**FN = 20**|**TP = 30**|\n",
        "\n",
        "\n",
        "**Note:** Every time you build a prediction model, the predictions might be slightly different from the previous ones. Hence, the confusion matrix might have slightly different values every time.\n",
        "\n",
        "These values of confusion matrix are used for calculating precision, recall and f1-score with the below formulae:\n",
        "\n",
        "1. **Precision** - It is the ratio of the correctly predicted positive values (TP) to the total predicted positive values (TP + FP) i.e.\n",
        "\n",
        "$$\\text{precision} = \\frac{\\text{TP}}{\\text{TP + FP}}$$\n",
        "\n",
        "\n",
        "2. **Recall** -  It is the ratio of the correctly predicted positive values (TP)values to the total values (TP + FN) i.e. \n",
        "\n",
        "$$\\text{recall} = \\frac{\\text{TP}}{\\text{TP + FN}}$$\n",
        "\n",
        "\n",
        "3. **f1-score** - It is a harmonic mean of the precision and recall values, i.e.\n",
        "\n",
        "$$\\text{f1-score} = 2 \\left( \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}} \\right)$$\n",
        "\n",
        "Let's take a look at precision, recall and f1-score of our model using `classification_report()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMH7f---UTVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f9003f0-43f7-499e-f192-3b402c07655a"
      },
      "source": [
        "# S4.4: Display the precision, recall and f1-score values.\n",
        "print(classification_report(y_test, rf_y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.59      0.56        41\n",
            "           1       0.64      0.60      0.62        50\n",
            "\n",
            "    accuracy                           0.59        91\n",
            "   macro avg       0.59      0.59      0.59        91\n",
            "weighted avg       0.60      0.59      0.59        91\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ4fM1guUjtr"
      },
      "source": [
        "We can see that the **f1-scores** for both the labels `0` and `1` are not closed to 1. Thus, the prediction percentage is not satisfactory.  \n",
        "\n",
        "Let's verify accuracy with another classification based machine learning model **Logistic Regression**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxrVzP-_0kah"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_poi12der_F"
      },
      "source": [
        "#### Activity 5: Logistic Regression^^^\n",
        "\n",
        "Logistic Regression is a type of **classification** algorithm which classifies or categorises a given set of data into different class labels. In the context of heart disease dataset, logistic regression will  classify the patients either as `1` (having heart disease) or as `0` (not having heart disease).\n",
        "\n",
        "Logistic Regression is used to predict the probability of an outcome for an event. It calculates a threshold probability value. If the probability of an outcome is less than the threshold probability, then logistic regression classifies that outcome as `0`, otherwise as `1`. You will learn the technical details in the subsequent classes, but for the time being, let's build a Logistic Regression model on the train set by following the steps listed below:\n",
        "\n",
        "1. Import `LogisticRegression` class from the `sklearn.linear_model` module. \n",
        "2. Create an object of the `LogisticRegression` class, say `log_reg` and pass `n_jobs = -1` as input to its constructor.\n",
        "3. Call the `fit()` function of the `LogisticRegression` class on the object created and pass `X_train` and `y_train` as inputs to the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxtlCGgAeUkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e565f88c-ea6b-4e54-94c0-86ce071c2693"
      },
      "source": [
        "# T5.1: Deploy the 'LogisticRegression' model using the 'fit()' function.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression(n_jobs = -1)\n",
        "\n",
        "log_reg.fit(X_train, y_train)\n",
        "log_reg.score(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5283018867924528"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXuBKlKC0EE5"
      },
      "source": [
        "The accuracy score is less than the one obtained through `RandomForestClassifier` . However, let's make the predictions on the test set and compare them with the actual labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JMQlyNOfDAq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54355c46-19de-4d19-db3d-ef45e95dd46e"
      },
      "source": [
        "# S5.1: Make predictions on the test dataset by using the 'predict()' function.\n",
        "log_y_pred = log_reg.predict(X_test)\n",
        "log_y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUWZiyrF0EE-"
      },
      "source": [
        "Let's compute the confusion matrix to calculate recall, precision and f1-scores \n",
        "to evaluate the logistic regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r24aTqpxfnQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "738b865b-0306-44bb-f142-d58e444b1eda"
      },
      "source": [
        "# S5.2: Display the confusion_matrix.\n",
        "confusion_matrix(y_test, log_y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2, 39],\n",
              "       [ 0, 50]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO8P9HHCfnQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a95dc3-a1ae-4415-9d23-a9995719d12a"
      },
      "source": [
        "# S5.3: Display recall, precision and f1-score values.\n",
        "print(classification_report(y_test, log_y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.05      0.09        41\n",
            "           1       0.56      1.00      0.72        50\n",
            "\n",
            "    accuracy                           0.57        91\n",
            "   macro avg       0.78      0.52      0.41        91\n",
            "weighted avg       0.76      0.57      0.44        91\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxU0ezJVsqvy"
      },
      "source": [
        "The f1-score is high for class `1` which are true positives are correctly obtained through Logistic Regression. But true negatives are very low. The Random Forest Classifier model is able to get more true negatives. So both of them are unable to provide high number of true positive and high number of true negatives.\n",
        "\n",
        "You will soon get to learn how both these models work behind the scenes and then you will develop a sense of which classification model to use for different kinds of problem statements. \n",
        "\n",
        "Let us predict the labels with both classifiers on some arbitrary cholesterol values, say 180 and 260."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B97SLEbh8yP5",
        "outputId": "0fca2168-dd8a-4c1f-c4fb-e8ee0b7dc5a1"
      },
      "source": [
        "# S5.4: Predict labels with cholesterol levels 180 and 260 for both models\n",
        "# Using Random Forest Classifier\n",
        "print(f\"Prediction of Random Forest Classification with cholesterol = 180: {rf_clf.predict(np.array(180).reshape(-1, 1))}\")\n",
        "print(f\"Prediction of Random Forest Classification with cholesterol = 260: {rf_clf.predict(np.array(260).reshape(-1, 1))}\")\n",
        "\n",
        "# Using Logistic Regression\n",
        "print(f\"\\nPrediction of Logistic Regression Classification with cholesterol = 180: {log_reg.predict(np.array(180).reshape(-1, 1))}\")\n",
        "print(f\"Prediction of Logistic Regression Classification with cholesterol = 260: {log_reg.predict(np.array(260).reshape(-1, 1))}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction of Random Forest Classification with cholesterol = 180: [1]\n",
            "Prediction of Random Forest Classification with cholesterol = 260: [0]\n",
            "\n",
            "Prediction of Logistic Regression Classification with cholesterol = 180: [1]\n",
            "Prediction of Logistic Regression Classification with cholesterol = 260: [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlR83AHU0ne_"
      },
      "source": [
        "Let's stop here, in the next class, we will understand the working of Logistic Regression algorithm using sigmoid function and will also try to improve the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GObBg7R3zT9g"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3Bn0cODJT19"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fb2_S47ALnT"
      },
      "source": [
        "## Additional Activities\n",
        "\n",
        "The activities starting from this point are optional. Please do these activities **ONLY** if you have time to spare in the class. Otherwise, skip to the **Wrap-Up** section. The additional activities will not be available in the class copy of the notebook. You will have to manually add these activities in the class copy by adding new text and code cells.\n",
        "\n",
        "Moreover, you don't have to do all the additional activities. Depending on the availability of time in a class, you can choose the number of additional activities to perform from this collection. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwSCxMT5ArfX"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMqI_rSEAsE0"
      },
      "source": [
        "#### Activity 1: Feature Scaling\n",
        "\n",
        "Let's first normalise the cholesterol values using the standard scaling methood and then build the logistic regression model again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WelJsSwBHq6",
        "outputId": "f4f80ff2-252d-4654-bfb4-33bed7c26044"
      },
      "source": [
        "# S1.1: Normalise the 'chol' column values using the standard scaler method.\n",
        "def standard_scaler(array):\n",
        "  new_array = (array - np.mean(array)) / np.std(array)\n",
        "  return new_array\n",
        "\n",
        "X_train_scaled = standard_scaler(X_train)\n",
        "X_test_scaled = standard_scaler(X_test)\n",
        "\n",
        "print(\"Train scaled:\\n\", X_train_scaled[:5], \"\\n\\nTest scaled:\\n\", X_test_scaled[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train scaled:\n",
            " [[-0.88680513]\n",
            " [-0.79502487]\n",
            " [-0.51968408]\n",
            " [-0.15256304]\n",
            " [-1.32735038]] \n",
            "\n",
            "Test scaled:\n",
            " [[ 0.72077507]\n",
            " [ 0.98958872]\n",
            " [-2.63939558]\n",
            " [ 3.70012637]\n",
            " [ 0.47436255]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqAY4ta9BeRu",
        "outputId": "4a5ceb4c-d1b2-4fb9-95e4-cd0208ab514e"
      },
      "source": [
        "# S1.2: Build the logistic regression model after scaling the cholesterol values.\n",
        "\n",
        "log_reg2 = LogisticRegression(n_jobs = -1)\n",
        "\n",
        "log_reg2.fit(X_train_scaled, y_train)\n",
        "log_reg2.score(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5235849056603774"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyRv-RDkB5sP",
        "outputId": "64198bb1-f646-4c94-f277-06b0f9e53b6e"
      },
      "source": [
        "# S1.3: Predict the target values for the test set.\n",
        "log2_y_pred = log_reg.predict(X_test_scaled)\n",
        "log2_y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNIg_aGQCXLr",
        "outputId": "62dbb66e-b913-4c2d-d251-88f348551ed7"
      },
      "source": [
        "# S1.4: Print the confusion_matrix.\n",
        "confusion_matrix(y_test, log2_y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0, 41],\n",
              "       [ 0, 50]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6hHrdyDCZX2",
        "outputId": "72f218b3-6c65-4cc3-bc12-d40d46f0fd68"
      },
      "source": [
        "# S1.5: Print the recall, precision and f1-score values.\n",
        "print(classification_report(y_test, log2_y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        41\n",
            "           1       0.55      1.00      0.71        50\n",
            "\n",
            "    accuracy                           0.55        91\n",
            "   macro avg       0.27      0.50      0.35        91\n",
            "weighted avg       0.30      0.55      0.39        91\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASpyWJveAK2N"
      },
      "source": [
        "---"
      ]
    }
  ]
}